# -*- coding: utf-8 -*-
"""Train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DWH-UMQXB1S58fUQxmODVwBkd8gaYKZX
"""





import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
from tqdm import tqdm
from torch.utils.data import DataLoader
 
 
class Train:
    def __init__(self, architecture, DirectoryTrain, DirectoryValid, params):
        self.cuda = params['cuda']
        if self.cuda:
            self.architecture = architecture.cuda()
        else:
            self.architecture = architecture
        self.DirectoryTrain = DirectoryTrain
        self.DirectoryValid = DirectoryValid
        self.NoiseModel = params['NoiseModel']
        self.ImageCropSize = params['ImageCropSize']
        self.CleanTargets = params['CleanTargets']
        self.lr = params['lr']
        self.epochs = params['epochs']
        self.bs = params['bs']
        self.train_dl, self.val_dl = self.__getdataset__()
        self.optimizer = self.__getoptimizer__()
        self.scheduler = self.__getscheduler__()
        self.loss_fn = self.__getlossfn__(params['lossfn'])
 
    
    def train(self):
        for _ in range(self.epochs):
            tr_loss = 0
            self.architecture.train()
            for _list in tqdm(self.train_dl):
                if self.cuda:
                    source = _list[0].cuda()
                    target = _list[-1].cuda()
                else:
                    source = _list[0]
                    target = _list[-1]
                _op = self.architecture(Variable(source))
                if len(_list) == 4:
                    if self.cuda:
                        mask = Variable(_list[1].cuda())
                    else:
                        mask = Variable(_list[1])
                    _loss = self.loss_fn(mask * _op, mask * Variable(target))
                else:
                    _loss = self.loss_fn(_op, Variable(target))
                tr_loss += _loss.data
 
                self.optimizer.zero_grad()
                _loss.backward()
                self.optimizer.step()
            
            val_loss = self.evaluate()
            print(f'Training loss = {tr_loss}, Validation loss = {val_loss}')